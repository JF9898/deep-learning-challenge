{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_counts = application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "cutoff = 500\n",
    "application_types_to_replace = application_counts[application_counts < cutoff].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_counts = application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "classification_counts[classification_counts > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "cutoff = 1000\n",
    "classifications_to_replace = classification_counts[classification_counts < cutoff].index.tolist()\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                       0   \n",
       "1       1   108590              1                       0   \n",
       "2       1     5000              0                       0   \n",
       "3       1     6692              1                       0   \n",
       "4       1   142590              1                       0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                     1                     0                    0   \n",
       "1                     0                     0                    1   \n",
       "2                     0                     0                    0   \n",
       "3                     0                     0                    1   \n",
       "4                     0                     0                    1   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    0                    0                    0  ...   \n",
       "1                    0                    0                    0  ...   \n",
       "2                    0                    1                    0  ...   \n",
       "3                    0                    0                    0  ...   \n",
       "4                    0                    0                    0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  0                       0                         0   \n",
       "1                  1                       0                         0   \n",
       "2                  0                       0                         0   \n",
       "3                  0                       1                         0   \n",
       "4                  0                       0                         1   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   0                 0                       0   \n",
       "1                   0                 0                       0   \n",
       "2                   0                 0                       0   \n",
       "3                   0                 0                       0   \n",
       "4                   0                 0                       0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                0                  0                         1   \n",
       "1                0                  0                         1   \n",
       "2                0                  0                         1   \n",
       "3                0                  0                         1   \n",
       "4                0                  0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "application_dummies = pd.get_dummies(application_df)\n",
    "application_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = application_dummies.drop('IS_SUCCESSFUL', axis=1).values\n",
    "y = application_dummies['IS_SUCCESSFUL'].values\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                3520      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,981\n",
      "Trainable params: 5,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 3s 2ms/step - loss: 0.5717 - accuracy: 0.7212\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5553 - accuracy: 0.7301\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5517 - accuracy: 0.7313\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5502 - accuracy: 0.7330\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5494 - accuracy: 0.7348\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5479 - accuracy: 0.7343\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5479 - accuracy: 0.7328\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7348\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7350\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7345\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7355\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5454 - accuracy: 0.7355\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7353\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7355\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7353\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7361\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7365\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7365\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7357\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7376\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7373\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7358\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7366\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7376\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7381\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5419 - accuracy: 0.7379\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5414 - accuracy: 0.7377\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7380\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5413 - accuracy: 0.7381\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7390\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5412 - accuracy: 0.7379\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5406 - accuracy: 0.7385\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5406 - accuracy: 0.7389\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5405 - accuracy: 0.7387\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5407 - accuracy: 0.7386\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5404 - accuracy: 0.7393\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7387\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5402 - accuracy: 0.7388\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5399 - accuracy: 0.7398\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5396 - accuracy: 0.7396\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5397 - accuracy: 0.7396\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5395 - accuracy: 0.7395\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5393 - accuracy: 0.7397\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5388 - accuracy: 0.7397\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5391 - accuracy: 0.7397\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5386 - accuracy: 0.7403\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5387 - accuracy: 0.7400\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5392 - accuracy: 0.7396\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5387 - accuracy: 0.7402\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5384 - accuracy: 0.7400\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5384 - accuracy: 0.7400\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5381 - accuracy: 0.7394\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5383 - accuracy: 0.7404\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5382 - accuracy: 0.7400\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5384 - accuracy: 0.7395\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5379 - accuracy: 0.7404\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5378 - accuracy: 0.7398\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5377 - accuracy: 0.7398\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5377 - accuracy: 0.7398\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5376 - accuracy: 0.7394\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5380 - accuracy: 0.7410\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5375 - accuracy: 0.7404\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5374 - accuracy: 0.7402\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7405\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5372 - accuracy: 0.7401\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5372 - accuracy: 0.7408\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5371 - accuracy: 0.7407\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5369 - accuracy: 0.7416\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5371 - accuracy: 0.7414\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5368 - accuracy: 0.7404\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5372 - accuracy: 0.7411\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5368 - accuracy: 0.7406\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7403\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5365 - accuracy: 0.7403\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5366 - accuracy: 0.7402\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5365 - accuracy: 0.7410\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5364 - accuracy: 0.7409\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 5s 6ms/step - loss: 0.5365 - accuracy: 0.7405\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5364 - accuracy: 0.7411\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5365 - accuracy: 0.7407\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5363 - accuracy: 0.7411\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5362 - accuracy: 0.7409\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5366 - accuracy: 0.7407\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5362 - accuracy: 0.7409\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5363 - accuracy: 0.7406\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5359 - accuracy: 0.7418\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.7403\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5360 - accuracy: 0.7409\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5358 - accuracy: 0.7413\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5358 - accuracy: 0.7411\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.7411\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.7411\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5360 - accuracy: 0.7413\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5356 - accuracy: 0.7425\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5356 - accuracy: 0.7408\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7411\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.7410\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5354 - accuracy: 0.7414\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5357 - accuracy: 0.7412\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5356 - accuracy: 0.7404\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5560 - accuracy: 0.7257 - 913ms/epoch - 3ms/step\n",
      "Loss: 0.5560162663459778, Accuracy: 0.7257142663002014\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fit_model.history['accuracy'])\n",
    "plt.plot(fit_model.history['loss'])\n",
    "plt.title('model accuracy and loss')\n",
    "plt.ylabel('accuracy and loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# The accuracy is at 72.5% and the loss is at 0.55. This is not a good model. We need to try to improve the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 7)                 308       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 14)                112       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 435\n",
      "Trainable params: 435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#fine tune the model\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  7\n",
    "hidden_nodes_layer2 = 14\n",
    "#hidden_nodes_layer3 = 1\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "#nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 4s 2ms/step - loss: 0.5987 - accuracy: 0.7076\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5635 - accuracy: 0.7289\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5590 - accuracy: 0.7294\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5563 - accuracy: 0.7308\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5549 - accuracy: 0.7304\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5540 - accuracy: 0.7308\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5531 - accuracy: 0.7317\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5525 - accuracy: 0.7317\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5521 - accuracy: 0.7324\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5509 - accuracy: 0.7323\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5506 - accuracy: 0.7328\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5502 - accuracy: 0.7328\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5500 - accuracy: 0.7331\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7329\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5493 - accuracy: 0.7332\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5485 - accuracy: 0.7338\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5486 - accuracy: 0.7334\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5484 - accuracy: 0.7334\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5481 - accuracy: 0.7334\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5480 - accuracy: 0.7331\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5478 - accuracy: 0.7329\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7339\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5473 - accuracy: 0.7344\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5471 - accuracy: 0.7333\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5468 - accuracy: 0.7338\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5469 - accuracy: 0.7353\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7352\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5462 - accuracy: 0.7345\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5466 - accuracy: 0.7349\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5463 - accuracy: 0.7343\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5464 - accuracy: 0.7345\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7352\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5464 - accuracy: 0.7352\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5463 - accuracy: 0.7352\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5464 - accuracy: 0.7348\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7350\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7356\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5459 - accuracy: 0.7348\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5460 - accuracy: 0.7348\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7352\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7356\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5458 - accuracy: 0.7348\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7348\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7360\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7344\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5456 - accuracy: 0.7351\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5453 - accuracy: 0.7354\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7352\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.7352\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5457 - accuracy: 0.7344\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5450 - accuracy: 0.7343\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5454 - accuracy: 0.7353\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7360\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7355\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7348\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7367\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7354\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5453 - accuracy: 0.7344\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5452 - accuracy: 0.7356\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5453 - accuracy: 0.7356\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7365\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5454 - accuracy: 0.7356\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5448 - accuracy: 0.7348\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7354\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7352\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7353\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7357\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.7364\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7363\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7359\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7361\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7355\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7354\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7358\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7357\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7362\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5448 - accuracy: 0.7352\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5446 - accuracy: 0.7363\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5440 - accuracy: 0.7365\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5445 - accuracy: 0.7363\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5444 - accuracy: 0.7362\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7365\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7367\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7358\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7366\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7365\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7356\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7357\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7359\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7358\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7361\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7360\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7364\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5440 - accuracy: 0.7362\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7357\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.7364\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7367\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5438 - accuracy: 0.7357\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5531 - accuracy: 0.7275 - 611ms/epoch - 2ms/step\n",
      "Loss: 0.5530908107757568, Accuracy: 0.7274635434150696\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "#there is no improvement in the model. The accuracy is at 72.5% and the loss is at 0.55. This is not a good model. We need to try to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 7)                 308       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 14)                112       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 21)                315       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 757\n",
      "Trainable params: 757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#fine tune the model\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  7\n",
    "hidden_nodes_layer2 = 14\n",
    "hidden_nodes_layer3 = 21\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 4s 3ms/step - loss: 0.6045 - accuracy: 0.6870\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5664 - accuracy: 0.7252\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5599 - accuracy: 0.7273\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5573 - accuracy: 0.7296\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5553 - accuracy: 0.7301\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5547 - accuracy: 0.7313\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5543 - accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5538 - accuracy: 0.7320\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5533 - accuracy: 0.7306\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5523 - accuracy: 0.7316\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5520 - accuracy: 0.7318\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5525 - accuracy: 0.7311\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5514 - accuracy: 0.7318\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5512 - accuracy: 0.7323\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5510 - accuracy: 0.7312\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5507 - accuracy: 0.7322\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5508 - accuracy: 0.7323\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5505 - accuracy: 0.7316\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5499 - accuracy: 0.7332\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5495 - accuracy: 0.7331\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5495 - accuracy: 0.7325\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5486 - accuracy: 0.7313\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5484 - accuracy: 0.7330\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5485 - accuracy: 0.7331\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5479 - accuracy: 0.7332\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5478 - accuracy: 0.7330\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5477 - accuracy: 0.7336\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5476 - accuracy: 0.7337\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5475 - accuracy: 0.7345\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5472 - accuracy: 0.7337\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5473 - accuracy: 0.7343\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5469 - accuracy: 0.7341\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5466 - accuracy: 0.7350\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5468 - accuracy: 0.7342\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5465 - accuracy: 0.7331\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5464 - accuracy: 0.7331\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5464 - accuracy: 0.7345\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7345\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5465 - accuracy: 0.7344\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5460 - accuracy: 0.7346\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5455 - accuracy: 0.7350\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5457 - accuracy: 0.7348\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7354\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5457 - accuracy: 0.7351\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5452 - accuracy: 0.7351\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5454 - accuracy: 0.7346\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5454 - accuracy: 0.7361\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5454 - accuracy: 0.7347\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5452 - accuracy: 0.7355\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5452 - accuracy: 0.7355\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7366\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5453 - accuracy: 0.7360\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5450 - accuracy: 0.7355\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5449 - accuracy: 0.7356\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5448 - accuracy: 0.7354\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5449 - accuracy: 0.7367\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7358\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7358\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7352\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5443 - accuracy: 0.7357\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7366\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5446 - accuracy: 0.7361\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5448 - accuracy: 0.7356\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5442 - accuracy: 0.7352\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5442 - accuracy: 0.7355\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5441 - accuracy: 0.7359\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5441 - accuracy: 0.7368\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5437 - accuracy: 0.7362\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5439 - accuracy: 0.7363\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7357\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7361\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7356\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5438 - accuracy: 0.7364\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5438 - accuracy: 0.7367\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.7359\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5436 - accuracy: 0.7361\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 5s 7ms/step - loss: 0.5436 - accuracy: 0.7357\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5434 - accuracy: 0.7352\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5437 - accuracy: 0.7361\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5440 - accuracy: 0.7364\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5435 - accuracy: 0.7361\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5437 - accuracy: 0.7364\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5433 - accuracy: 0.7356\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5434 - accuracy: 0.7355\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5434 - accuracy: 0.7361\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 4s 5ms/step - loss: 0.5436 - accuracy: 0.7365\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5435 - accuracy: 0.7358\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5432 - accuracy: 0.7363\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5434 - accuracy: 0.7365\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5433 - accuracy: 0.7364\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5430 - accuracy: 0.7364\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5432 - accuracy: 0.7363\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5433 - accuracy: 0.7365\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5431 - accuracy: 0.7364\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5429 - accuracy: 0.7372\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5429 - accuracy: 0.7360\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5429 - accuracy: 0.7353\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5430 - accuracy: 0.7361\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 3s 4ms/step - loss: 0.5429 - accuracy: 0.7367\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 4s 4ms/step - loss: 0.5428 - accuracy: 0.7364\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 1s - loss: 0.5527 - accuracy: 0.7216 - 1s/epoch - 5ms/step\n",
      "Loss: 0.5527360439300537, Accuracy: 0.7216326594352722\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try to automate the process of finding the best number of hidden layers and nodes using keras tuner\n",
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_model(hp):\n",
    "    # Define the input layer\n",
    "    input_layer = Input(shape=(X_train.shape[1],))\n",
    "    \n",
    "    # Define the number of neurons in the first layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    \n",
    "    # Add the first Dense layer with ReLU activation\n",
    "    hidden_layer = Dense(units=hp_units, activation='relu')(input_layer)\n",
    "    \n",
    "    # Add additional hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        hp_units = hp.Int(f'units_{i}', min_value=32, max_value=512, step=32)\n",
    "        hidden_layer = Dense(units=hp_units, activation='relu')(hidden_layer)\n",
    "    \n",
    "    # Define the output layer\n",
    "    output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the kerastuner library\n",
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=50,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180 Complete [00h 02m 44s]\n",
      "val_accuracy: 0.7265306115150452\n",
      "\n",
      "Best val_accuracy So Far: 0.7274635434150696\n",
      "Total elapsed time: 02h 03m 47s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# optimize the model\n",
    "tuner.search(X_train_scaled,y_train,epochs=50,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x2a1af7d39d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "#Even when trying to automate using keras tuner, the accuracy is at 72.7% and the loss is at 0.55. \n",
    "#I am not sure how else to improve the model. I have tried to change the activation function, the optimizer, the number of epochs, the number of hidden layers and the number of nodes in each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
